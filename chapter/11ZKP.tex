\chapter{零知识证明和论证系统}\label{chp:11ZKP}

\section{什么是零知识证明？}\label{11.1}
零知识证明或论证的定义刻画了这样一个概念，即验证者除了被证明的陈述的有效性之外，不应该从证明者那里学到任何东西。 \footnote{回顾一下，一个证明系统满足统计可靠性，而一个论证系统满足计算可靠性。 参见定义 \ref{def:3.1} 和 \ref{def:3.2}。} 
也就是说，验证者通过与诚实的证明者交互中学到的任何信息，都可以由验证者自己学到，而无需访问证明者。 
这需要通过模拟来形式化的，即要求有一种称为\dotemph{模拟器}的有效算法，该算法仅输入要证明的陈述，产生的脚本分布与和验证者与一个诚实证明者交互时产生的脚本分布无法区分（回顾 \ref{3.1} 节，交互式协议的脚本指协议执行期间证明者和验证者交换的所有消息的列表）。

\begin{definition}[零知识的非正式定义] \label{def:11.1}
    对于语言 $\mathcal{L}$，一个具有证明者 $\mathcal{P}$ 和验证者 $\mathcal{V}$ 的证明或论证系统被称为是零知识的，如果对于任意概率多项式时间验证者策略 $\hat{V}$，存在一个概率多项式时间算法 $S$（可以依赖于 $\hat{V}$），称为模拟器，使得对于所有 $x \in \mathcal{L}$ ，模拟器的输出分布$S(x)$ 与 $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}( x))$“不可区分”。 $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}(x))$ 表示由证明或论证系统中的证明者策略 $\mathcal{P}$ 和验证者策略 $\hat{V}$交互产生的脚本的分布。
\end{definition}

非正式地说，模拟器的存在意味着除了学习到 $x \in \mathcal{L}$ 之外，验证者 $\mathcal{V}$ 不会从证明者那里学到任何超出 $\mathcal{V}$ 可以自己高效地计算的东西。 
这是因为，以$x$ 在 $\mathcal{L}$ 中为条件，$\mathcal{V}$ 无法区分通过与诚实证明者交互生成的脚本与通过忽略证明者并运行模拟器所生成的脚本。 
因此，验证者可以从证明者那里学到的任何信息也可以从模拟器中学到（这是一个高效程序，因此验证者可以负担得起自己运行模拟器）。

定义\ref{def:11.1}中的术语“不可区分”有三种自然的意义：

\begin{itemize}
    \item One possibility is to require that $S(x)$ and $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}(x))$ are literally the same distribution. In this case, the proof or argument system is said to be perfect-zero knowledge..$^{134}$
    \item Another possibility is to require that the distributions $S(x)$ and $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}(x))$ have negligible statistical distance. In this case, the proof or argument system is said to be statistical zero-knowledge. Here, the statistical distance (also called total variation distance) between two distributions $D_1$ and $D_2$ is defined to be
    $$
    \frac{1}{2} \sum_y\left|\operatorname{Pr}\left[D_1(x)=y\right]-\operatorname{Pr}\left[D_2(x)=y\right]\right|,
    $$
    and it equals the maximum over all algorithms $\mathcal{A}$ (including inefficient algorithms) of
    $$
    \left|\underset{y \leftarrow D_1}{\operatorname{Pr}}[\mathcal{A}(y)=1]-\underset{y \leftarrow D_2}{\operatorname{Pr}}[\mathcal{A}(y)=1]\right|,
    $$
    where $y \leftarrow D_i$ means that $y$ is a random draw from the distribution $D_i$. Hence, if two distributions have negligible statistical distance, then no algorithm (regardless of its runtime) can distinguish the two distributions with non-negligible probability given a polynomial number of samples from the distributions.
    \item The third possibility is to require that all polynomial time algorithms $\mathcal{A}$ cannot distinguish the distributions $S(x)$ and $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}(x))$ except with negligible probability, when given as input a polynomial number of samples from the distributions. In this case, the proof or argument system is said to be computational zero-knowledge.
\end{itemize}

Accordingly, when someone refers to a "zero-knowledge protocol", there are actually at least 6 types of protocols they may be referring to. This is because soundness comes in two flavors-statistical (proofs) and computational (arguments) - and zero-knowledge comes in at least 3 flavors (perfect, statistical, and computational). In fact, there are even more subtleties to be aware of when considering how to define the notion of zero-knowledge.
- (Honest vs. dishonest verifier zero-knowledge). Definition 11.1 requires an efficient simulator for every possible probabilistic polynomial time verifier strategy $\hat{V}$. This is referred to as maliciousor dishonest-verifier- zero knowledge (though papers often omit the clarifying phrase malicious or dishonest-verifier). It is also interesting to consider only requiring an efficient simulator for the prescribed verifier strategy $\mathcal{V}$. This is referred to as honest-verifier zero-knowledge.
- (Plain zero-knowledge vs. auxiliary-input zero-knowledge). Definition 11.1 considers the verifier $\hat{V}$ to have only one input, namely the public input $x$. This is referred to as plain zero-knowledge, and was the original definition given in the conference paper of Goldwasser, Micali, and Rackoff [GMR89] that introduced the notion of zero-knowledge (along with the notion of interactive proofs). However, when zero-knowledge proofs and arguments are used as subroutines within larger cryptographic protocols, one is typically concerned about dishonest verifiers that may compute their messages to the prover based on information acquired from the larger protocol prior to executing the zero-knowledge protocol. To capture such a setting, one must modify Definition 11.1 to refer to verifier strategies $\hat{V}$ that take two inputs: the public input $x$ known to both the prover and verifier, and an auxiliary input $z$ known only to the verifier and simulator, and insist that the output $S(x, z)$ of the simulator is "indistinguishable" from $\operatorname{View}_{\hat{V}}(\mathcal{P}(x), \hat{V}(x, z))$. This modified definition is referred to as auxiliary-input zero-knowledge. Of course, the distinction between auxiliary-input and plain zero-knowledge is only relevant when considering dishonest verifiers.

An added benefit of considering auxiliary-input computational zero-knowledge is that this notion is closed under sequential composition. This means that if one runs several protocols satisfying auxiliary-input computational zero-knowledge, one after the other, the resulting protocol remains auxiliary-input computational zero-knowledge. This is actually not true for plain computational zeroknowledge, though known counterexamples are somewhat contrived. The interested reader is directed to [BV10] and the references therein for a relatively recent study of the composition properties of zero-knowledge proofs and arguments.

The reader may be momentarily panicked at the fact that we have now roughly 24 notions of zeroknowledge protocols, one for every possible combination of (statistical vs. computational soundness), (perfect vs. statistical vs. computational zero-knowledge), (honest-verifier vs. dishonest-verifier zeroknowledge), and (plain vs. auxiliary input zero-knowledge). That's $2 \cdot 3 \cdot 2 \cdot 2$ combinations in total, though for honest-verifier notions of zero-knowledge the difference between auxiliary-input and plain zeroknowledge is irrelevant. Fortunately for us, there are only a handful of variants that we will have reason to study in this manuscript, summarized below.

In Sections 11.2-11.4 below, we briefly discuss statistical zero-knowledge proofs. Our discussion is short because, as we explain, statistical zero-knowledge proofs are not very powerful (e.g., while they are capable of solving some problems believed to be outside of BPP, they are not believed to be able to solve NP-complete problems). Roughly all we do is describe what is known about their limitations, and then give a sense of what they are capable of computing by presenting two simple examples: a classic zeroknowledge proof system for graph non-isomorphism due to [GMW91] (Section 11.3), and a particularly elegant protocol for a problem called the Collision Problem (this problem is somewhat contrived, but the protocol is an instructive example of the power of zero-knowledge).

In subsequent chapters, we present a variety of perfect zero-knowledge arguments. All are non-interactive (possibly after applying the Fiat-Shamir transformation), rendering the distinction between malicious- and honest-verifier (and auxiliary-input vs. plain) zero-knowledge irrelevant. ${ }^{135136137}$

\subsubsection{关于模拟} A common source of confusion for those first encountering zero-knowledge is to wonder whether an efficient simulator for the honest verifier’s view in a zero-knowledge proof or argument for a language $\mathcal{L}$ implies that the problem can be solved by an efficient algorithm (with no prover). That is, given input $x$, why can't one run the simulator $S$ on $x$ several times and try to discern from the transcripts output by $S$ whether or not $x \in \mathcal{L}$ ? The answer is that this would require that for every pair of inputs $\left(x, x^{\prime}\right)$ with $x \in \mathcal{L}$ and $x^{\prime} \notin \mathcal{L}$, the distributions $S(x)$ and $S\left(x^{\prime}\right)$ are efficiently distinguishable. Nothing in the definition of zero-knowledge guarantees this. In fact, the definition of zero-knowledge says nothing about how the simulator $S$ behaves on inputs $x^{\prime}$ that are not in $\mathcal{L}$.

Indeed, it is entirely possible that an efficient simulator $S$ can produce accepting transcripts for a zeroknowledge protocol even when run on inputs $x^{\prime} \notin \mathcal{L}$. Similarly, in the context of zero-knowledge proofs of knowledge, where the prover is claiming to know a witness $w$ satisfying some property, the simulator will be able to produce accepting transcripts without knowing a witness.

One may initially wonder whether the preceding paragraph contradicts soundness of the protocol: if the simulator can find accepting transcripts for false claims, can't a cheating prover somehow use those transcripts to convince the verifier to accept false claims as valid? The answer is no. One reason for this is that a zero-knowledge protocol may be interactive, yet the simulator only needs to produce convincing transcripts of the interaction. This means that the simulator is able to do things like first choose all of the verifier's challenges, and then choose all of the prover's messages in a manner that depends on those challenges. In contrast, a cheating prover must send its message in each round prior to learning the verifier's challenge in that round. So even if the simulator can find accepting transcripts for inputs $x \notin \mathcal{L}$, it will be of no help to a dishonest prover trying to convince $\mathcal{V}$ that $x \in \mathcal{L}$. This will be the situation for the simulators we construct in Section 11.4 for the Collision Problem, and the zero-knowledge proofs of knowledge that we develop in Section 12.2 (e.g., in Schnorr's protocol for establishing knowledge of a discrete logarithm). ${ }^{138}$

\subsubsection{一些最后的直观} Some final intuition. Another way of thinking about a zero-knowledge protocol is as follows. If the prover $\mathcal{P}$ convinces the verifier $\mathcal{V}$ to accept, then $\mathcal{V}$ can infer (unless $\mathcal{P}$ got very lucky in terms of the random challenges the verifier happened to send to the prover during the interaction) that $\mathcal{P}$ must have had an effective strategy for answering verifier challenges. That is, $\mathcal{P}$ must have been prepared to successfully answer many different challenges that $\mathcal{V}$ might have asked (but did not actually ask) during the protocol's execution. If the protocol has low soundness error, this implies that $\mathcal{P}$ 's claim is accurate, i.e., that $x \in \mathcal{L}$.
Meanwhile, zero-knowledge guarantees that $\mathcal{P}$ 's answers to the actual challenges asked by $\mathcal{V}$ during the protocol reveal no other information whatsoever. Put another way, $\mathcal{P}$ 's answers to the challenges sent during the zero-knowledge protocol are only useful for convincing $\mathcal{V}$ that $\mathcal{P}$ was prepared to answer other challenges that were not actually asked. $\mathcal{P}$ 's preparation reveals to $\mathcal{V}$ that $\mathcal{P}$ 's claim is accurate, but reveals nothing else.

This intuition will become clearer in Section 12.2, when we cover so-called special-sound protocols. These are three-message protocols in which the verifier $\mathcal{V}$ sends a single random challenge to the prover (this challenge is the protocol's second message). Following the prover's first message, if $\mathcal{V}$ were somehow able to obtain the prover's answers to two different challenges, then $\mathcal{V}$ would indeed learn information from the two responses. This does not violate zero-knowledge because the verifier in the protocol only interacts with $\mathcal{P}$ once, and can only send a single challenge during that interaction.



\section{统计零知识证明的局限}\label{11.2}
\section{对图的非同构的诚实验证者统计零知识证明协议}\label{11.3}
\section{对碰撞问题的诚实验证者统计零知识证明协议}\label{11.4}